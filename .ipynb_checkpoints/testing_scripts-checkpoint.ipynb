{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_upkW4iQ-3JI"
   },
   "source": [
    "### Call individual functions for the component they are testing (currently does not need to do anything else)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "LYmptBQY-9b1"
   },
   "outputs": [],
   "source": [
    "# Should read in files that would be used for testing (should represent idealized output that the function would receive)\n",
    "# Results should be saved in a variable so they can be evaluated\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R5ucCuE0nJdD"
   },
   "source": [
    "### Testing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18981,
     "status": "ok",
     "timestamp": 1699071465285,
     "user": {
      "displayName": "SHARON TAM",
      "userId": "04253875606491539255"
     },
     "user_tz": 420
    },
    "id": "h3XkfMykOUiD",
    "outputId": "054fb0b3-1bbd-4329-d479-0e10a244d3bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mne in /Users/sharontam/opt/anaconda3/lib/python3.9/site-packages (1.3.1)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /Users/sharontam/opt/anaconda3/lib/python3.9/site-packages (from mne) (1.9.1)\n",
      "Requirement already satisfied: decorator in /Users/sharontam/opt/anaconda3/lib/python3.9/site-packages (from mne) (5.1.1)\n",
      "Requirement already satisfied: matplotlib in /Users/sharontam/opt/anaconda3/lib/python3.9/site-packages (from mne) (3.5.2)\n",
      "Requirement already satisfied: tqdm in /Users/sharontam/opt/anaconda3/lib/python3.9/site-packages (from mne) (4.64.1)\n",
      "Requirement already satisfied: pooch>=1.5 in /Users/sharontam/opt/anaconda3/lib/python3.9/site-packages (from mne) (1.7.0)\n",
      "Requirement already satisfied: jinja2 in /Users/sharontam/opt/anaconda3/lib/python3.9/site-packages (from mne) (2.11.3)\n",
      "Requirement already satisfied: packaging in /Users/sharontam/opt/anaconda3/lib/python3.9/site-packages (from mne) (21.3)\n",
      "Requirement already satisfied: numpy>=1.15.4 in /Users/sharontam/opt/anaconda3/lib/python3.9/site-packages (from mne) (1.21.6)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /Users/sharontam/opt/anaconda3/lib/python3.9/site-packages (from pooch>=1.5->mne) (2.5.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in /Users/sharontam/opt/anaconda3/lib/python3.9/site-packages (from pooch>=1.5->mne) (2.28.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/sharontam/opt/anaconda3/lib/python3.9/site-packages (from packaging->mne) (3.0.9)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /Users/sharontam/opt/anaconda3/lib/python3.9/site-packages (from jinja2->mne) (2.0.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/sharontam/opt/anaconda3/lib/python3.9/site-packages (from matplotlib->mne) (4.25.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/sharontam/opt/anaconda3/lib/python3.9/site-packages (from matplotlib->mne) (0.11.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/sharontam/opt/anaconda3/lib/python3.9/site-packages (from matplotlib->mne) (9.2.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/sharontam/opt/anaconda3/lib/python3.9/site-packages (from matplotlib->mne) (1.4.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/sharontam/opt/anaconda3/lib/python3.9/site-packages (from matplotlib->mne) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/sharontam/opt/anaconda3/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib->mne) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/sharontam/opt/anaconda3/lib/python3.9/site-packages (from requests>=2.19.0->pooch>=1.5->mne) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/sharontam/opt/anaconda3/lib/python3.9/site-packages (from requests>=2.19.0->pooch>=1.5->mne) (1.26.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/sharontam/opt/anaconda3/lib/python3.9/site-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/sharontam/opt/anaconda3/lib/python3.9/site-packages (from requests>=2.19.0->pooch>=1.5->mne) (2023.7.22)\n",
      "Collecting umap-learn\n",
      "  Using cached umap_learn-0.5.4-py3-none-any.whl\n",
      "Requirement already satisfied: tqdm in /Users/sharontam/opt/anaconda3/lib/python3.9/site-packages (from umap-learn) (4.64.1)\n",
      "Requirement already satisfied: scikit-learn>=0.22 in /Users/sharontam/opt/anaconda3/lib/python3.9/site-packages (from umap-learn) (1.0.2)\n",
      "Collecting pynndescent>=0.5\n",
      "  Using cached pynndescent-0.5.10-py3-none-any.whl\n",
      "Requirement already satisfied: numba>=0.51.2 in /Users/sharontam/opt/anaconda3/lib/python3.9/site-packages (from umap-learn) (0.55.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/sharontam/opt/anaconda3/lib/python3.9/site-packages (from umap-learn) (1.21.6)\n",
      "Collecting tbb>=2019.0\n",
      "  Using cached tbb-2021.10.0-py2.py3-none-macosx_10_15_x86_64.macosx_11_0_x86_64.whl (640 kB)\n",
      "Requirement already satisfied: scipy>=1.3.1 in /Users/sharontam/opt/anaconda3/lib/python3.9/site-packages (from umap-learn) (1.9.1)\n",
      "Requirement already satisfied: setuptools in /Users/sharontam/opt/anaconda3/lib/python3.9/site-packages (from numba>=0.51.2->umap-learn) (63.4.1)\n",
      "Requirement already satisfied: llvmlite<0.39,>=0.38.0rc1 in /Users/sharontam/opt/anaconda3/lib/python3.9/site-packages (from numba>=0.51.2->umap-learn) (0.38.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /Users/sharontam/opt/anaconda3/lib/python3.9/site-packages (from pynndescent>=0.5->umap-learn) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/sharontam/opt/anaconda3/lib/python3.9/site-packages (from scikit-learn>=0.22->umap-learn) (2.2.0)\n",
      "Installing collected packages: tbb, pynndescent, umap-learn\n",
      "  Attempting uninstall: tbb\n",
      "    Found existing installation: TBB 0.2\n",
      "\u001b[31mERROR: Cannot uninstall 'TBB'. It is a distutils installed project and thus we cannot accurately determine which files belong to it which would lead to only a partial uninstall.\u001b[0m\u001b[31m\n",
      "\u001b[0mRequirement already satisfied: pyedflib in /Users/sharontam/opt/anaconda3/lib/python3.9/site-packages (0.1.30)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /Users/sharontam/opt/anaconda3/lib/python3.9/site-packages (from pyedflib) (1.21.6)\n",
      "Collecting xgboost\n",
      "  Downloading xgboost-2.0.2-py3-none-macosx_10_15_x86_64.macosx_11_0_x86_64.macosx_12_0_x86_64.whl (2.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: scipy in /Users/sharontam/opt/anaconda3/lib/python3.9/site-packages (from xgboost) (1.9.1)\n",
      "Requirement already satisfied: numpy in /Users/sharontam/opt/anaconda3/lib/python3.9/site-packages (from xgboost) (1.21.6)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-2.0.2\n"
     ]
    }
   ],
   "source": [
    "!pip install mne\n",
    "!pip install umap-learn\n",
    "!pip install pyedflib\n",
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "2KgUpTm5OU8p"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'umap'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/8y/rlnkhh_n15j03j5khf924ktw0000gn/T/ipykernel_19817/3168796624.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mXGBClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmake_classification\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mumap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mumap_\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mumap\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'umap'"
     ]
    }
   ],
   "source": [
    "import mne\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.io as sio\n",
    "from scipy.signal import periodogram\n",
    "import pywt\n",
    "from collections import Counter\n",
    "from tqdm.notebook import tqdm\n",
    "import scipy.stats as stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV, GroupKFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "import umap.umap_ as umap\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from glob import glob\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import shutil\n",
    "from scipy.signal import welch\n",
    "#from utils import *\n",
    "import logging\n",
    "import zipfile\n",
    "import pyedflib\n",
    "from pyedflib import highlevel\n",
    "import io\n",
    "import tempfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1706,
     "status": "ok",
     "timestamp": 1699071486728,
     "user": {
      "displayName": "SHARON TAM",
      "userId": "04253875606491539255"
     },
     "user_tz": 420
    },
    "id": "pX9BLFNAvjcv",
    "outputId": "922cbdd6-60d9-4d07-a445-e75ac9750eb0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/gdrive/Shareddrives/BE_223A_Seizure_Project/Code/seizureai-main\n",
      "/Users/andresmichel/Documents/EGG data /v2.0.0/edf/dev\n"
     ]
    }
   ],
   "source": [
    "# Import processing functions\n",
    "\n",
    "# [UPDATE PATH]\n",
    "%cd /content/gdrive/Shareddrives/BE_223A_Seizure_Project/Code/seizureai-main/\n",
    "\n",
    "# Now, you can import your module\n",
    "from dataset import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HCkZn9v6vlpl"
   },
   "outputs": [],
   "source": [
    "# In the future this will be a full folder, but for now it will be one edf file\n",
    "\n",
    "# [UPDATE PATH]\n",
    "data_file_path  = '/content/gdrive/Shareddrives/BE_223A_Seizure_Project/Code/aaaaaajy_s001_t000.edf'\n",
    "labels = [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14304,
     "status": "ok",
     "timestamp": 1699071501028,
     "user": {
      "displayName": "SHARON TAM",
      "userId": "04253875606491539255"
     },
     "user_tz": 420
    },
    "id": "A1ZuryqDvnWs",
    "outputId": "ea76c3a5-f558-494b-815c-36184dce056b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/gdrive/Shareddrives/BE_223A_Seizure_Project/Code\n"
     ]
    }
   ],
   "source": [
    "# Import functions\n",
    "\n",
    "# [UPDATE PATH]\n",
    "# %cd  /content/gdrive/Shareddrives/BE_223A_Seizure_Project/Code/\n",
    "\n",
    "from classical_ml_models import *\n",
    "from get_features import *\n",
    "from train_test_tune import *\n",
    "from cnn import *\n",
    "from rnn import *\n",
    "from validate import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24,
     "status": "ok",
     "timestamp": 1699071501028,
     "user": {
      "displayName": "SHARON TAM",
      "userId": "04253875606491539255"
     },
     "user_tz": 420
    },
    "id": "mffJpaBGtUMD",
    "outputId": "f0f71588-40b4-4856-c449-73476189a6ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/gdrive/Shareddrives/BE_223A_Seizure_Project/Code/seizureai-main\n"
     ]
    }
   ],
   "source": [
    "# Import processing functions\n",
    "\n",
    "# [UPDATE PATH]\n",
    "%cd /content/gdrive/Shareddrives/BE_223A_Seizure_Project/Code/seizureai-main/\n",
    "\n",
    "# Now, you can import your module\n",
    "from dataset import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HJK_topEM9-m"
   },
   "source": [
    "### Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_6h3mqM0nSLv"
   },
   "outputs": [],
   "source": [
    "def eval_pre_processing(edf_path):\n",
    "\n",
    "  eeg_data_pair = EEGDataPair(data_file_path)\n",
    "\n",
    "  # Run the preprocessing pipeline\n",
    "  edf_file = eeg_data_pair.processing_pipeline()\n",
    "\n",
    "  # Store the original raw for visualization\n",
    "  raw_before = eeg_data_pair.raw.copy()\n",
    "\n",
    "  # Channels that are present after preprocessing\n",
    "  common_chs = [ch for ch in raw_before.ch_names if ch in eeg_data_pair.raw.ch_names]\n",
    "\n",
    "  # Same chanels for both plots\n",
    "  raw_before.pick_channels(common_chs)\n",
    "  eeg_data_pair.raw.pick_channels(common_chs)\n",
    "\n",
    "  # Visualize EEG data BEFORE preprocessing\n",
    "  raw_before.plot(title=\"Before Preprocessing\", n_channels=20, scalings=\"auto\", show=True)\n",
    "\n",
    "  # Visualize EEG data AFTER preprocessing\n",
    "  eeg_data_pair.raw.plot(title=\"After Preprocessing\", n_channels=20, scalings=\"auto\", show=True)\n",
    "\n",
    "  print(edf_file.shape)\n",
    "\n",
    "  print(edf_file.size)\n",
    "\n",
    "  return edf_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vr91Q3YoNCsz"
   },
   "source": [
    "### Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1699075994203,
     "user": {
      "displayName": "SOULAIMANE BENTALEB",
      "userId": "17889313387321949207"
     },
     "user_tz": 420
    },
    "id": "p63oeqVOiAIy"
   },
   "outputs": [],
   "source": [
    "# Test the get_features function by asserting it outputs a matrix with the right dimensions\n",
    "def eval_get_features(list_signals, wavelet_name):\n",
    "  features = get_features(list_signals, wavelet_name)\n",
    "  print('The features matrix has dimensions ' + str(features.shape))\n",
    "  if features.shape == (32, 177):\n",
    "    print('Those are the correct dimensions!')\n",
    "  if features.shape != (32, 177):\n",
    "    print('Those are the wrong dimensions! The correct dimensions are (32, 177)')\n",
    "  return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KGA-0hVlNE4b"
   },
   "source": [
    "### Classical ML Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MQOvcn3WNzeG"
   },
   "outputs": [],
   "source": [
    "def eval_tuning(data, labels, groups):\n",
    "  [params, best_params] = train_test_tune(data, labels, groups)\n",
    "\n",
    "  # Check the evaluation scores of each test parameter combination\n",
    "  svc_params = params[0].sort_values(by=['mean_test_score', ascending=False])\n",
    "  rf_params = params[1].sort_values(by=['mean_test_score', ascending=False])\n",
    "  kmeans_params = params[2].sort_values(by=['mean_test_score', ascending=False])\n",
    "  xg_params = params[3].sort_values(by=['mean_test_score', ascending=False])\n",
    "\n",
    "  svc_tune_scores = svc_params.mean_test_score\n",
    "  rf_tune_scores = rf_params.mean_test_score\n",
    "  kmeans_tune_scores = kmeans_params.mean_test_score\n",
    "  xg_tune_scores = xg_params.mean_test_score\n",
    "\n",
    "  best_svc_score = max(svc_tune_scores)\n",
    "  avg_svc_score = np.mean(svc_tune_scores)\n",
    "\n",
    "  best_rfscore = max(rf_tune_scores)\n",
    "  avg_rf_score = np.mean(rf_tune_scores)\n",
    "\n",
    "  best_kmeans_score = max(kmeans_tune_scores)\n",
    "  avg_kmeans_score = np.mean(kmeans_tune_scores)\n",
    "\n",
    "  best_xg_score = max(xg_tune_scores)\n",
    "  avg_xg_score = np.mean(xg_tune_scores)\n",
    "\n",
    "  print_result = \"\"\"\n",
    "  SVC Results:\n",
    "    Best score: {best_svc_score}\n",
    "    Average score: {avg_svc_score}\n",
    "    Best parameters: {svc_params.iloc[:3]}\n",
    "    \n",
    "  Random Forest Results:\n",
    "    Best score: {best_rf_score}\n",
    "    Average score: {avg_rf_score}\n",
    "    Best parameters: {rf_params.iloc[:3]}\n",
    "    \n",
    "  K Means Results:\n",
    "    Best score: {best_kmeans_score}\n",
    "    Average score: {avg_kmeans_score}\n",
    "    Best parameters: {kmeans_params.iloc[:3]}\n",
    "    \n",
    "  XG Boost Results:\n",
    "    Best score: {best_xg_score}\n",
    "    Average score: {avg_xg_score}\n",
    "    Best parameters: {xg_params.iloc[:3]} \"\"\"\n",
    "  \n",
    "  print(print_result)\n",
    "  \n",
    "  return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run with fake test data\n",
    "patients = 5\n",
    "files = 5*patients\n",
    "channels = 2\n",
    "features = 10\n",
    "data = np.random.rand(files, channels, features)\n",
    "labels = np.array([1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1])\n",
    "groups = np.array([0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4])\n",
    "\n",
    "# Return list of pd dataframes that contain every combo of parameters + mean_test_score\n",
    "# Return list of dict for each model with the best parameters\n",
    "eval_tuning(data, labels, groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AiV62_vzNIhS"
   },
   "source": [
    "### Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "an4Mv0vnPXHc"
   },
   "outputs": [],
   "source": [
    "def eval_rnn(data, labels, val_data, parameters):\n",
    "  predictions = rnn_model(data,labels, val_data,parameters)\n",
    "  return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ev8BHnpNm6Gz"
   },
   "outputs": [],
   "source": [
    "def eval_cnn(edf_file, labels):\n",
    "  weights = run_cnn(edf_file, labels)\n",
    "  return weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dGkuW1CfNOCL"
   },
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dVrYTXK2NQuo"
   },
   "outputs": [],
   "source": [
    "def eval_validation(train_data, train_labels, val_data, val_labels, parameters):\n",
    "\n",
    "  results = validate(train_data, train_labels, val_data, val_labels, parameters)\n",
    "\n",
    "  # Check that validation methods are working and returning results in proper format\n",
    "\n",
    "  return results"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
